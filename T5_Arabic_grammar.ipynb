{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9533840,"sourceType":"datasetVersion","datasetId":5806514}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-02T18:53:56.814410Z","iopub.execute_input":"2024-10-02T18:53:56.814742Z","iopub.status.idle":"2024-10-02T18:53:57.836606Z","shell.execute_reply.started":"2024-10-02T18:53:56.814706Z","shell.execute_reply":"2024-10-02T18:53:57.835750Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/quran/quran_texts.txt\n/kaggle/input/quran/scraping.py\n/kaggle/input/quran/README.md\n/kaggle/input/quran/Quran_Grammar.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers\n!pip install evaluate\n!pip install rouge\n\n\nimport torch\nimport json\nfrom tqdm import tqdm\nimport torch.nn as nn\nfrom torch.optim import Adam\nimport nltk\nimport spacy\nimport string\nimport evaluate  # Bleu\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler\nimport pandas as pd\nimport numpy as np\nimport transformers\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration, T5TokenizerFast\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:53:57.838628Z","iopub.execute_input":"2024-10-02T18:53:57.839178Z","iopub.status.idle":"2024-10-02T18:54:56.148664Z","shell.execute_reply.started":"2024-10-02T18:53:57.839132Z","shell.execute_reply":"2024-10-02T18:54:56.147638Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\nCollecting rouge\n  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\nDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\nInstalling collected packages: rouge\nSuccessfully installed rouge-1.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import MT5Tokenizer, MT5ForConditionalGeneration","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:54:56.149981Z","iopub.execute_input":"2024-10-02T18:54:56.150637Z","iopub.status.idle":"2024-10-02T18:54:56.166588Z","shell.execute_reply.started":"2024-10-02T18:54:56.150601Z","shell.execute_reply":"2024-10-02T18:54:56.165836Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"TOKENIZER = T5TokenizerFast.from_pretrained(\"t5-base\")\nMODEL = T5ForConditionalGeneration.from_pretrained(\"t5-base\", return_dict=True)\nOPTIMIZER = Adam(MODEL.parameters(), lr=0.00001)\nQ_LEN = 256   # Question Length\nT_LEN = 32    # Target Length\nBATCH_SIZE = 4\nDEVICE = \"cuda:0\"","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:54:56.168351Z","iopub.execute_input":"2024-10-02T18:54:56.168640Z","iopub.status.idle":"2024-10-02T18:55:01.409226Z","shell.execute_reply.started":"2024-10-02T18:54:56.168609Z","shell.execute_reply":"2024-10-02T18:55:01.408349Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b12e5784a894d01a7ad249cdb391c4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfe46623c6ca4ce7bc271ebe3de9586f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d484098c5e0049b6a178e093f6dbd564"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf28fa0706ad452a8c2e16bc3bf0af8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe9ae74fcaa24c11bae9eb2d61eea224"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Read data\n","metadata":{}},{"cell_type":"code","source":"data_path=\"/kaggle/input/quran/Quran_Grammar.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:55:01.410481Z","iopub.execute_input":"2024-10-02T18:55:01.410782Z","iopub.status.idle":"2024-10-02T18:55:01.415160Z","shell.execute_reply.started":"2024-10-02T18:55:01.410750Z","shell.execute_reply":"2024-10-02T18:55:01.414192Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(data_path,sep=';')","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:55:01.416553Z","iopub.execute_input":"2024-10-02T18:55:01.417275Z","iopub.status.idle":"2024-10-02T18:55:01.498465Z","shell.execute_reply.started":"2024-10-02T18:55:01.417228Z","shell.execute_reply":"2024-10-02T18:55:01.497553Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data=df.drop(columns='surah')","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:55:01.499768Z","iopub.execute_input":"2024-10-02T18:55:01.500213Z","iopub.status.idle":"2024-10-02T18:55:01.512663Z","shell.execute_reply.started":"2024-10-02T18:55:01.500162Z","shell.execute_reply":"2024-10-02T18:55:01.511713Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data['grammar'][0]","metadata":{"execution":{"iopub.status.busy":"2024-10-02T19:02:28.765385Z","iopub.execute_input":"2024-10-02T19:02:28.766126Z","iopub.status.idle":"2024-10-02T19:02:28.772091Z","shell.execute_reply.started":"2024-10-02T19:02:28.766085Z","shell.execute_reply":"2024-10-02T19:02:28.771189Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'﴿بِسْمِ﴾ جار ومجرور متعلق بفعل محذوف تقديره: أبدأ أو بدأت، وحذفت الألف لكثرة الاستعمال. [أو أن شبه الجملة متعلق بمحذوف خبر، والمبتدأ محذوف تقديره: ابتدائي]. ﴿اللهِ﴾: لفظ الجلالة مضاف إليه مجرور. ﴿الرَّحْمنِ﴾: نعت مجرور للفظ الجلالة. ﴿الرَّحِيمِ﴾: نعت ثان مجرور. والجملة الفعلية: (أبدأ) بسم الله ... ابتدائية.'"},"metadata":{}}]},{"cell_type":"code","source":"class QA_Dataset(Dataset):\n    def __init__(self, tokenizer, dataframe, q_len, t_len):\n        self.tokenizer = tokenizer\n        self.q_len = q_len\n        self.t_len = t_len\n        self.data = dataframe\n        self.questions = self.data[\"verse\"]\n        self.answer = self.data['grammar']\n        \n    def __len__(self):\n        return len(self.questions)\n    \n    def __getitem__(self, idx):\n        question = self.questions[idx]\n        answer = self.answer[idx]\n        \n        question_tokenized = self.tokenizer(question, max_length=self.q_len, padding=\"max_length\",\n                                                    truncation=True, pad_to_max_length=True, add_special_tokens=True)\n        answer_tokenized = self.tokenizer(answer, max_length=self.t_len, padding=\"max_length\", \n                                          truncation=True, pad_to_max_length=True, add_special_tokens=True)\n        \n        labels = torch.tensor(answer_tokenized[\"input_ids\"], dtype=torch.long)\n        labels[labels == 0] = -100\n        \n        return {\n            \"input_ids\": torch.tensor(question_tokenized[\"input_ids\"], dtype=torch.long),\n            \"attention_mask\": torch.tensor(question_tokenized[\"attention_mask\"], dtype=torch.long),\n            \"labels\": labels,\n            \"decoder_attention_mask\": torch.tensor(answer_tokenized[\"attention_mask\"], dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:55:01.536815Z","iopub.execute_input":"2024-10-02T18:55:01.537178Z","iopub.status.idle":"2024-10-02T18:55:01.546654Z","shell.execute_reply.started":"2024-10-02T18:55:01.537120Z","shell.execute_reply":"2024-10-02T18:55:01.545793Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_data, val_data = train_test_split(data, test_size=0.1, random_state=42)\n\ntrain_sampler = RandomSampler(train_data.index)\nval_sampler = RandomSampler(val_data.index)\n\nqa_dataset = QA_Dataset(TOKENIZER, data, Q_LEN, T_LEN)\n\ntrain_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\nval_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, sampler=val_sampler)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:55:01.547687Z","iopub.execute_input":"2024-10-02T18:55:01.548105Z","iopub.status.idle":"2024-10-02T18:55:01.560791Z","shell.execute_reply.started":"2024-10-02T18:55:01.548066Z","shell.execute_reply":"2024-10-02T18:55:01.559956Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"MODEL.to(DEVICE)\n\ntrain_loss = 0\nval_loss = 0\ntrain_batch_count = 0\nval_batch_count = 0\n\nfor epoch in range(2):\n    MODEL.train()\n    for batch in tqdm(train_loader, desc=\"Training batches\"):\n        input_ids = batch[\"input_ids\"].to(DEVICE)\n        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n        labels = batch[\"labels\"].to(DEVICE)\n        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n\n        outputs = MODEL(\n                          input_ids=input_ids,\n                          attention_mask=attention_mask,\n                          labels=labels,\n                          decoder_attention_mask=decoder_attention_mask\n                        )\n\n        OPTIMIZER.zero_grad()\n        outputs.loss.backward()\n        OPTIMIZER.step()\n        train_loss += outputs.loss.item()\n        train_batch_count += 1\n    \n    #Evaluation\n    MODEL.eval()\n    for batch in tqdm(val_loader, desc=\"Validation batches\"):\n        input_ids = batch[\"input_ids\"].to(DEVICE)\n        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n        labels = batch[\"labels\"].to(DEVICE)\n        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n\n        outputs = MODEL(\n                          input_ids=input_ids,\n                          attention_mask=attention_mask,\n                          labels=labels,\n                          decoder_attention_mask=decoder_attention_mask\n                        )\n\n        OPTIMIZER.zero_grad()\n        outputs.loss.backward()\n        OPTIMIZER.step()\n        val_loss += outputs.loss.item()\n        val_batch_count += 1\n        \n    print(f\"{epoch+1}/{2} -> Train loss: {train_loss / train_batch_count}\\tValidation loss: {val_loss/val_batch_count}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-02T18:56:03.173368Z","iopub.execute_input":"2024-10-02T18:56:03.173797Z","iopub.status.idle":"2024-10-02T18:57:44.977771Z","shell.execute_reply.started":"2024-10-02T18:56:03.173757Z","shell.execute_reply":"2024-10-02T18:57:44.976554Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Training batches: 100%|██████████| 242/242 [00:46<00:00,  5.24it/s]\nValidation batches: 100%|██████████| 27/27 [00:04<00:00,  5.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"1/2 -> Train loss: 0.7325732884081927\tValidation loss: 0.5122765843515042\n","output_type":"stream"},{"name":"stderr","text":"Training batches: 100%|██████████| 242/242 [00:45<00:00,  5.33it/s]\nValidation batches: 100%|██████████| 27/27 [00:04<00:00,  5.46it/s]","output_type":"stream"},{"name":"stdout","text":"2/2 -> Train loss: 0.6343242319777977\tValidation loss: 0.48585209360829107\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"def predict_answer(question, ref_answer=None):\n    inputs = TOKENIZER(question, max_length=Q_LEN, padding=\"max_length\", truncation=True, add_special_tokens=True)\n    \n    input_ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n    attention_mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n\n    outputs = MODEL.generate(input_ids=input_ids, attention_mask=attention_mask)\n  \n    predicted_answer = TOKENIZER.decode(outputs.flatten(), skip_special_tokens=True)\n    \n    if ref_answer:\n        # Load the Bleu metric\n        bleu = evaluate.load(\"google_bleu\")\n        score = bleu.compute(predictions=[predicted_answer], \n                            references=[ref_answer])\n    \n        print(\"Context: \\n\", context)\n        print(\"\\n\")\n        print(\"Question: \\n\", question)\n        return {\n            \"Reference Answer: \": ref_answer, \n            \"Predicted Answer: \": predicted_answer, \n            \"BLEU Score: \": score\n        }\n    else:\n        return predicted_answer","metadata":{"execution":{"iopub.status.busy":"2024-10-02T19:01:19.828537Z","iopub.execute_input":"2024-10-02T19:01:19.828968Z","iopub.status.idle":"2024-10-02T19:01:19.837947Z","shell.execute_reply.started":"2024-10-02T19:01:19.828929Z","shell.execute_reply":"2024-10-02T19:01:19.836937Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"predict_answer(\"بسم الله الرحمن الحيم \",\"سْمِ﴾ جار ومجرور متعلق بفعل محذوف تقديره: أبدأ أو بدأت، وحذفت الألف لكثرة الاستعمال. [أو أن شبه الجملة متعلق بمحذوف خبر، والمبتدأ محذوف تقديره: ابتدائي]. ﴿اللهِ﴾: لفظ الجلالة مضاف إليه مجرور. ﴿الرَّحْمنِ﴾: نعت مجرور للفظ الجلالة. ﴿الرَّحِيمِ﴾: نعت ثان مجرور. والجملة الفعلية: (أبدأ) بسم الله ... ابتدائية\") ","metadata":{"execution":{"iopub.status.busy":"2024-10-02T19:02:49.212833Z","iopub.execute_input":"2024-10-02T19:02:49.213491Z","iopub.status.idle":"2024-10-02T19:02:50.885663Z","shell.execute_reply.started":"2024-10-02T19:02:49.213451Z","shell.execute_reply":"2024-10-02T19:02:50.884277Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.64k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e7ab89c750a43af8d74f33daf0f6905"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14cb4e55c84f432bad54bd2a20c3ed63"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/util.py:468\u001b[0m, in \u001b[0;36mngrams\u001b[0;34m(sequence, n, pad_left, pad_right, left_pad_symbol, right_pad_symbol)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 468\u001b[0m     history\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    469\u001b[0m     n \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n","\u001b[0;31mStopIteration\u001b[0m: ","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredict_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mبسم الله الرحمن الحيم \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mسْمِ﴾ جار ومجرور متعلق بفعل محذوف تقديره: أبدأ أو بدأت، وحذفت الألف لكثرة الاستعمال. [أو أن شبه الجملة متعلق بمحذوف خبر، والمبتدأ محذوف تقديره: ابتدائي]. ﴿اللهِ﴾: لفظ الجلالة مضاف إليه مجرور. ﴿الرَّحْمنِ﴾: نعت مجرور للفظ الجلالة. ﴿الرَّحِيمِ﴾: نعت ثان مجرور. والجملة الفعلية: (أبدأ) بسم الله ... ابتدائية\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n","Cell \u001b[0;32mIn[13], line 14\u001b[0m, in \u001b[0;36mpredict_answer\u001b[0;34m(question, ref_answer)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ref_answer:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Load the Bleu metric\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     bleu \u001b[38;5;241m=\u001b[39m evaluate\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle_bleu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mbleu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mpredicted_answer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mref_answer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContext: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, context)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/evaluate/module.py:467\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {input_name: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[input_name] \u001b[38;5;28;01mfor\u001b[39;00m input_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m temp_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed):\n\u001b[0;32m--> 467\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompute_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_writer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--google_bleu/6fc70b7be0088120a372dfdd5d320b39b8bb3630cb8029b193941d9376e86bb0/google_bleu.py:165\u001b[0m, in \u001b[0;36mGoogleBleu._compute\u001b[0;34m(self, predictions, references, tokenizer, min_len, max_len)\u001b[0m\n\u001b[1;32m    162\u001b[0m references \u001b[38;5;241m=\u001b[39m [[tokenizer(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m ref] \u001b[38;5;28;01mfor\u001b[39;00m ref \u001b[38;5;129;01min\u001b[39;00m references]\n\u001b[1;32m    163\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [tokenizer(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m predictions]\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle_bleu\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mgleu_score\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus_gleu\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlist_of_references\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreferences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypotheses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_len\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m }\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/translate/gleu_score.py:158\u001b[0m, in \u001b[0;36mcorpus_gleu\u001b[0;34m(list_of_references, hypotheses, min_len, max_len)\u001b[0m\n\u001b[1;32m    155\u001b[0m corpus_n_all \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m references, hypothesis \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(list_of_references, hypotheses):\n\u001b[0;32m--> 158\u001b[0m     hyp_ngrams \u001b[38;5;241m=\u001b[39m \u001b[43mCounter\u001b[49m\u001b[43m(\u001b[49m\u001b[43meverygrams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     tpfp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(hyp_ngrams\u001b[38;5;241m.\u001b[39mvalues())  \u001b[38;5;66;03m# True positives + False positives.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     hyp_counts \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/collections/__init__.py:577\u001b[0m, in \u001b[0;36mCounter.__init__\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Create a new, empty Counter object.  And if given, count elements\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;124;03mfrom an input iterable.  Or, initialize the count from another mapping\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03mof elements to their counts.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    574\u001b[0m \n\u001b[1;32m    575\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m--> 577\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/collections/__init__.py:670\u001b[0m, in \u001b[0;36mCounter.update\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mupdate(iterable)\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m         \u001b[43m_count_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds:\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(kwds)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/util.py:535\u001b[0m, in \u001b[0;36meverygrams\u001b[0;34m(sequence, min_len, max_len, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m     max_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sequence)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(min_len, max_len\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ng \u001b[38;5;129;01min\u001b[39;00m ngrams(sequence, n, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    536\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m ng\n","\u001b[0;31mRuntimeError\u001b[0m: generator raised StopIteration"],"ename":"RuntimeError","evalue":"generator raised StopIteration","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}